# 分段锁并发能力量化分析

## 核心问题

1. **分段锁能支持多少并发？**
2. **如果不是分段锁（全局锁），能支持多少并发？**
3. **有没有量化分段锁效果的数据？**

## 并发度定义

**并发度**：在同一时刻可以同时执行的操作数量。

### 分段锁的并发度

**当前配置**：`shardCount = 32`

**理论最大并发度**：**32**

**原因**：
- 32个分段，每个分段有独立的锁
- 不同分段之间可以并发访问
- 理论上最多可以同时有32个不同资源的操作并发执行

### 全局锁的并发度

**理论最大并发度**：**1**

**原因**：
- 只有一个全局锁
- 所有操作都需要竞争这个锁
- 同一时刻只能有一个操作执行

## 量化对比分析（修正版：考虑锁释放机制）

### ⚠️ 重要修正

之前的分析没有考虑到**锁会被释放**这个关键因素。锁的持有时间非常短（微秒级），真正的差异在于**业务操作能否并发执行**。

### 锁持有时间分析

**⚠️ 重要：以下数值是假设，不是实测值**

**分段锁和全局锁的持有时间相同**（假设）：
- TryLock: **1-10微秒**（假设，基于内存操作的典型性能）
- Unlock: **10-100微秒**（假设，基于内存操作的典型性能）

**假设依据**：
- TryLock和Unlock都是内存操作（map查找、结构体更新）
- 不涉及网络IO或磁盘IO
- 基于Go语言`sync.Mutex`的典型性能

**关键**：锁持有时间相对于业务操作时间（秒级）可以忽略不计！

**⚠️ 注意**：实际耗时需要通过基准测试验证（见 `docs/ASSUMPTIONS_AND_CONCLUSIONS.md`）

### 场景1：理想情况（资源均匀分布）

**假设**：
- N个不同资源的请求
- 资源均匀分布到32个分段（**假设**：理想情况）
- 每个业务操作耗时 T 秒（例如：镜像下载10秒，**假设**：示例值）
- 锁竞争时间：N × 1微秒（**基于假设1-10微秒的推理**）

#### 全局锁（无分段）

```
锁竞争时间：N × 1微秒（基于假设的推理）
业务操作：并发执行（锁释放后）
总耗时：N × 1微秒 + T ≈ T（如果N不大）
并发度：业务操作可以并发（锁释放后）
```

**✅ 结论**：业务操作可以并发执行，差异在于锁竞争时间

#### 分段锁（32个分段）

```
锁竞争时间：max(各分段) ≈ N/32 × 1微秒（基于假设的推理）
业务操作：并发执行（锁释放后）
总耗时：N/32 × 1微秒 + T ≈ T（如果N不大）
并发度：业务操作可以并发（锁释放后）
```

**✅ 结论**：业务操作可以并发执行，差异在于锁竞争时间（分段锁更短）

**示例计算**（基于假设：业务操作耗时10秒，TryLock耗时1微秒）：

| 资源数量 | 全局锁总耗时 | 分段锁总耗时 | 性能差异 |
|---------|------------|------------|---------|
| 32 | 10.000032秒 | 10.000001秒 | **0.031毫秒** |
| 64 | 10.000064秒 | 10.000002秒 | **0.062毫秒** |
| 100 | 10.0001秒 | 10.000003秒 | **0.097毫秒** |
| 320 | 10.00032秒 | 10.00001秒 | **0.31毫秒** |

**✅ 结论**：
- 业务操作都可以并发执行（锁释放后）
- 差异主要来自锁竞争时间（分段锁更短）
- 对于不同资源的请求，差异很小（毫秒级），相对于业务操作时间（秒级）可以忽略

**⚠️ 注意**：
- 以上计算基于假设值（TryLock耗时1微秒）
- 实际值需要通过基准测试验证（见 `docs/ASSUMPTIONS_AND_CONCLUSIONS.md`）

### 场景2：实际情况（资源分布不均匀）

**假设**：
- N个不同资源的请求
- 资源可能不均匀分布（哈希冲突）
- 每个业务操作耗时 T 秒
- 锁竞争时间：N × 1微秒 ≈ 0（可忽略）

#### 最坏情况：所有资源都哈希到同一个分段

```
锁竞争时间：N × 1微秒 ≈ 0（可忽略）
业务操作：串行执行（退化为全局锁）
总耗时：N × T 秒
并发度：1（业务操作串行）
性能提升：0倍（无提升）
```

#### 平均情况：资源相对均匀分布

假设资源分布的标准差为 σ，平均每个分段的请求数为 N/32：

```
锁竞争时间：N × 1微秒 ≈ 0（可忽略）
业务操作：并发执行（32个分段）
并发度：32（理想）到 1（最坏）
总耗时：max(各分段业务操作时间) ≈ max(各分段请求数) × T 秒
性能提升：1倍到32倍之间（取决于分布）
```

**示例计算**（100个资源，10秒业务操作耗时）：

| 分布情况 | 最忙分段请求数 | 业务操作时间 | 总耗时 | 性能提升 |
|---------|--------------|------------|--------|---------|
| 理想分布 | 3-4个 | 31.25秒 | 31.25秒 | **32倍** |
| 轻微不均匀 | 5-6个 | 50秒 | 50秒 | **20倍** |
| 中等不均匀 | 8-10个 | 80秒 | 80秒 | **12.5倍** |
| 严重不均匀 | 20个 | 200秒 | 200秒 | **5倍** |
| 最坏情况 | 100个 | 1000秒 | 1000秒 | **1倍**（无提升） |

**注意**：锁竞争时间（微秒级）已忽略，总耗时主要取决于业务操作时间。

### 场景3：实际业务场景

#### 场景A：镜像下载（100个不同层）

**假设**：
- 100个不同的镜像层（不同的 resourceID）
- 每个层下载耗时 10秒（业务操作时间）
- 使用32个分段
- 锁竞争时间：100 × 1微秒 ≈ 0（可忽略）

**全局锁**：
```
锁竞争时间：0.1毫秒（可忽略）
业务操作：串行执行
总耗时：100 × 10秒 = 1000秒（16.7分钟）
并发度：1（业务操作串行）
```

**分段锁**：
```
锁竞争时间：0.1毫秒（可忽略）
业务操作：并发执行（32个分段）
理想情况：100 / 32 × 10秒 ≈ 31.25秒
实际（考虑不均匀）：40-60秒
并发度：32（理想）
性能提升：16-32倍
```

#### 场景B：混合操作（50个pull + 50个delete）

**假设**：
- 50个pull操作，50个delete操作
- 每个业务操作耗时 5秒
- 使用32个分段
- 锁竞争时间：100 × 1微秒 ≈ 0（可忽略）

**全局锁**：
```
锁竞争时间：0.1毫秒（可忽略）
业务操作：串行执行
总耗时：100 × 5秒 = 500秒（8.3分钟）
并发度：1（业务操作串行）
```

**分段锁**：
```
锁竞争时间：0.1毫秒（可忽略）
业务操作：并发执行（32个分段）
理想情况：100 / 32 × 5秒 ≈ 15.6秒
实际（考虑不均匀）：20-30秒
并发度：32（理想）
性能提升：16-32倍
```

## 实际测试数据

### 测试场景：不同资源的并发操作

**测试代码**：`server/lock_manager_test.go:368`

**测试结果**：
- ✅ 不同资源可以并发操作
- ✅ 同一资源只能有一个节点成功
- ✅ 32个分段可以支持32个不同资源的并发操作

### 理论计算验证（修正版）

**公式**：
```
并发度 = min(shardCount, 不同资源数量)
锁竞争时间 = N × 1微秒 ≈ 0（可忽略）
业务操作时间 = max(各分段耗时) = max(各分段请求数) × 单业务操作耗时
总耗时 = 锁竞争时间 + 业务操作时间 ≈ 业务操作时间
性能提升 = 全局锁总耗时 / 分段锁总耗时
```

**示例**（100个不同资源，32个分段，10秒业务操作耗时）：

```
理想分布：
- 锁竞争时间：100 × 1微秒 = 0.1毫秒（可忽略）
- 每个分段：100/32 ≈ 3.125个请求
- 最忙分段：4个请求（向上取整）
- 业务操作时间：4 × 10秒 = 40秒
- 总耗时：40秒
- 性能提升：1000秒 / 40秒 = 25倍

实际分布（考虑哈希冲突）：
- 锁竞争时间：0.1毫秒（可忽略）
- 最忙分段：5-8个请求（常见）
- 业务操作时间：50-80秒
- 总耗时：50-80秒
- 性能提升：12.5-20倍
```

**关键**：锁竞争时间（微秒级）相对于业务操作时间（秒级）可以忽略不计。

## 分段数量对并发度的影响

### 不同分段数的并发能力

| 分段数 | 理论最大并发度 | 适用场景 | 内存开销 |
|--------|--------------|---------|---------|
| 1 | 1 | 全局锁，低并发 | 低 |
| 8 | 8 | 低并发（< 10个并发请求） | 低 |
| 16 | 16 | 中小并发（10-50个并发请求） | 中 |
| **32** | **32** | **中等并发（50-200个并发请求）** | **中** |
| 64 | 64 | 高并发（200-500个并发请求） | 高 |
| 128 | 128 | 极高并发（500-1000个并发请求） | 高 |
| 256 | 256 | 超高频并发（> 1000个并发请求） | 很高 |

### 分段数选择建议

**当前设置：32个分段**

**选择依据**：
1. **并发需求**：中等规模并发（几十到几百个并发请求）
2. **内存开销**：32个map，内存占用可接受
3. **哈希效率**：32是2的幂次方，取模运算高效
4. **实际场景**：镜像下载通常有几十到上百个层，32个分段足够

**调整建议**：

```go
// 根据实际并发需求调整
const shardCount = 32  // 当前设置，适合中等并发

// 如果并发需求更高，可以增加分段数
const shardCount = 64   // 高并发场景
const shardCount = 128  // 极高并发场景
```

## 性能提升量化数据

### 理论性能提升

**公式**：
```
性能提升 = 全局锁耗时 / 分段锁耗时
         = (N × T) / (max(各分段请求数) × T)
         = N / max(各分段请求数)
```

**理想情况**（资源均匀分布）：
```
性能提升 = N / (N/32) = 32倍
```

**实际情况**（资源不均匀分布）：
```
性能提升 = N / max(各分段请求数)
         = 1倍到32倍之间（取决于分布）
```

### 实际性能提升估算

**基于哈希分布均匀性**：

| 资源数量 | 理想提升 | 实际提升（估算） | 说明 |
|---------|---------|----------------|------|
| ≤ 32 | 1-N倍 | 接近理想值 | 资源数≤分段数，提升明显 |
| 32-100 | 32倍 | 20-30倍 | 轻微不均匀，提升显著 |
| 100-500 | 32倍 | 15-25倍 | 中等不均匀，提升明显 |
| 500-1000 | 32倍 | 10-20倍 | 较不均匀，仍有提升 |
| > 1000 | 32倍 | 5-15倍 | 严重不均匀，提升有限 |

**原因**：
- FNV-1a 哈希算法分布相对均匀
- 但实际分布可能不完全均匀
- 最忙分段可能比其他分段多2-3倍请求

## 并发度限制因素

### 1. 分段数量限制

**当前限制**：32个分段 → 理论最大并发度32

**提升方法**：增加分段数
```
shardCount = 64  → 最大并发度64
shardCount = 128 → 最大并发度128
```

### 2. 资源分布不均匀

**影响**：如果所有资源都哈希到少数分段，并发度会降低

**缓解方法**：
- 使用更好的哈希算法（FNV-1a已经很好）
- 增加分段数
- 监控分段负载，动态调整

### 3. 同一资源的竞争

**影响**：同一资源的多个请求会串行执行

**说明**：这是业务需求，不是性能问题
- 同一镜像层只能有一个节点操作
- 其他节点需要等待

## 实际业务场景分析

### 场景1：镜像下载（典型场景）

**特点**：
- 镜像通常有10-50个层
- 每个层是不同的资源（不同的 resourceID）
- 下载耗时较长（几秒到几分钟）

**并发度**：
```
全局锁：1（所有层串行下载）
分段锁：min(32, 层数)（不同层可以并发下载）

示例：50个层
- 全局锁：串行，总耗时 = 50 × 平均耗时
- 分段锁：32个分段，总耗时 ≈ 50/32 × 平均耗时
- 性能提升：约32倍（理想情况）
```

### 场景2：高并发场景（100+个不同资源）

**特点**：
- 大量不同的资源同时操作
- 资源分布可能不均匀

**并发度**：
```
全局锁：1
分段锁：32（理论最大）

实际：取决于资源分布
- 理想分布：接近32倍提升
- 不均匀分布：10-20倍提升
```

### 场景3：低并发场景（< 10个资源）

**特点**：
- 资源数量少
- 分段数可能过多

**并发度**：
```
全局锁：1
分段锁：min(32, 资源数)

示例：5个资源
- 全局锁：1
- 分段锁：5（实际只有5个分段被使用）
- 性能提升：5倍
```

**建议**：低并发场景可以使用更少的分段数（例如8个）

## 总结

### 并发度对比

| 锁类型 | 理论最大并发度 | 实际并发度 | 适用场景 |
|--------|--------------|-----------|---------|
| **全局锁** | **1** | **1** | 低并发，简单场景 |
| **分段锁（32）** | **32** | **10-32** | 中等并发，实际场景 |

### 性能提升量化

**当前配置（32个分段）**：

| 资源数量 | 理想提升 | 实际提升（估算） |
|---------|---------|----------------|
| ≤ 32 | 1-N倍 | 接近理想值 |
| 32-100 | 32倍 | **20-30倍** |
| 100-500 | 32倍 | **15-25倍** |
| 500-1000 | 32倍 | **10-20倍** |

### 关键结论

1. **分段锁理论最大并发度**：32（当前配置）
2. **全局锁理论最大并发度**：1
3. **实际性能提升**：10-30倍（取决于资源分布）
4. **适用场景**：中等规模并发（几十到几百个并发请求）

### 优化建议

1. **当前配置（32个分段）**：适合大多数场景
2. **高并发场景**：可以增加到64或128个分段
3. **低并发场景**：可以减少到8或16个分段
4. **监控分段负载**：根据实际分布调整分段数

