# 锁设计方案分析：分段锁 + 资源锁（真实锁）

## 方案对比

### 方案A：当前方案（分段锁 + 逻辑锁）

```go
type resourceShard struct {
    mu sync.RWMutex  // 分段锁（真实锁）
    
    locks map[string]*LockInfo  // 逻辑锁（状态标记）
    queues map[string][]*LockRequest
    subscribers map[string][]Subscriber
}
```

**特点：**
- 分段锁：保护数据结构的并发安全
- 逻辑锁：只是状态标记，不是真正的锁

### 方案B：新方案（分段锁 + 资源锁（真实锁））

```go
type resourceLock struct {
    mu sync.Mutex  // 资源锁（真实锁）
    
    lockInfo *LockInfo
    queue []*LockRequest
    subscribers []Subscriber
}

type resourceShard struct {
    mu sync.RWMutex  // 分段锁（真实锁）
    
    resourceLocks map[string]*resourceLock  // 每个资源一个真实锁
}
```

**特点：**
- 分段锁：保护资源锁的创建和访问
- 资源锁：每个资源一个真实互斥锁

## 可行性分析

### ✅ 优点

#### 1. **更细粒度的锁控制**
- **当前方案**：分段锁保护整个操作，即使只是读取状态也需要获取分段锁
- **新方案**：获取资源锁后，可以长时间持有，分段锁只用于创建/访问资源锁
- **好处**：减少分段锁的持有时间，提升并发度

#### 2. **更符合直觉的设计**
- 每个资源有自己独立的锁，逻辑更清晰
- 资源锁的生命周期与资源操作绑定

#### 3. **更好的锁粒度**
- 不同资源的操作完全独立，互不干扰
- 同一资源的操作通过资源锁互斥

### ⚠️ 潜在问题

#### 1. **内存开销增加**
- **当前方案**：只有 `LockInfo` 结构，内存占用小
- **新方案**：每个资源都有一个 `resourceLock` 结构，包含 `sync.Mutex`
- **影响**：如果资源数量很多（例如1000个镜像层），内存开销会增加

**估算：**
```
当前方案：
- LockInfo: ~100 bytes
- 1000个资源: 100 KB

新方案：
- resourceLock: ~200 bytes (包含 Mutex)
- 1000个资源: 200 KB
```

**结论**：内存开销增加，但在可接受范围内

#### 2. **分段锁的持有时间**
- **当前方案**：分段锁持有时间短（只用于检查状态）
- **新方案**：需要先获取分段锁，再获取资源锁，然后释放分段锁
- **问题**：如果资源锁不存在，需要创建，此时分段锁需要持有更长时间

**代码示例：**
```go
// 新方案
shard.mu.Lock()  // 1. 获取分段锁
rl := shard.getOrCreateResourceLock(key)  // 2. 获取或创建资源锁
shard.mu.Unlock()  // 3. 释放分段锁
rl.mu.Lock()  // 4. 获取资源锁
// ... 操作 ...
rl.mu.Unlock()  // 5. 释放资源锁
```

**对比：**
```go
// 当前方案
shard.mu.Lock()  // 1. 获取分段锁
// ... 检查状态、更新状态 ...
shard.mu.Unlock()  // 2. 释放分段锁
```

**结论**：新方案需要两次锁操作，但分段锁持有时间更短

#### 3. **资源锁的清理**
- **当前方案**：资源锁（逻辑锁）不存在时，map中也没有记录
- **新方案**：资源锁对象需要显式清理，否则会内存泄漏

**问题**：
- 操作完成后，资源锁对象需要从 map 中删除
- 如果忘记清理，会导致内存泄漏

**解决方案**：
```go
// 操作完成后清理
shard.mu.Lock()
delete(shard.resourceLocks, key)
shard.mu.Unlock()
```

**结论**：需要仔细处理资源锁的生命周期

#### 4. **死锁风险**
- **当前方案**：只有分段锁，死锁风险低
- **新方案**：分段锁 + 资源锁，需要避免死锁

**潜在死锁场景：**
```
线程1：获取分段锁A → 尝试获取资源锁R1
线程2：获取分段锁B → 尝试获取资源锁R2
如果 R1 和 R2 有依赖关系，可能死锁
```

**解决方案**：
- 始终按相同顺序获取锁（先分段锁，再资源锁）
- 分段锁只用于创建/访问资源锁，不用于业务逻辑

**结论**：需要仔细设计锁的获取顺序

## 性能分析

### 场景1：不同资源的并发操作

**假设**：100个不同资源的请求

**当前方案：**
```
- 100个请求分布到32个分段
- 每个分段平均3-4个请求
- 分段锁竞争：中等
- 总耗时：~31ms（理论值）
```

**新方案：**
```
- 100个请求分布到32个分段
- 每个分段平均3-4个请求
- 分段锁竞争：低（持有时间短）
- 资源锁竞争：无（不同资源）
- 总耗时：~25ms（理论值，分段锁持有时间更短）
```

**结论**：新方案性能略好

### 场景2：同一资源的并发操作

**假设**：10个节点请求同一个资源

**当前方案：**
```
- 10个请求都到同一个分段
- 分段锁竞争：高
- 第一个请求获得锁，其他9个进入队列
- 总耗时：取决于操作时间
```

**新方案：**
```
- 10个请求都到同一个分段
- 分段锁竞争：低（只用于创建资源锁）
- 资源锁竞争：高（同一资源）
- 第一个请求获得资源锁，其他9个等待资源锁
- 总耗时：取决于操作时间
```

**结论**：性能相近，但新方案分段锁竞争更少

### 场景3：混合场景（不同资源 + 同一资源）

**假设**：50个不同资源 + 10个同一资源

**当前方案：**
```
- 50个不同资源：可以并发（不同分段）
- 10个同一资源：串行（同一分段）
- 分段锁竞争：中等
```

**新方案：**
```
- 50个不同资源：可以并发（不同资源锁）
- 10个同一资源：串行（同一资源锁）
- 分段锁竞争：低
- 资源锁竞争：只在同一资源时发生
```

**结论**：新方案性能更好

## 实现复杂度

### 当前方案
- **复杂度**：低
- **代码量**：少
- **维护成本**：低

### 新方案
- **复杂度**：中等
- **代码量**：增加（需要管理资源锁的生命周期）
- **维护成本**：中等（需要处理资源锁的创建和清理）

## 适用场景分析

### 当前场景特点
1. **资源数量**：可能很多（镜像层可能有成百上千个）
2. **并发度**：需要支持高并发（不同资源可以并发）
3. **操作时间**：操作时间可能很长（镜像下载可能需要几分钟）
4. **队列机制**：需要 FIFO 队列
5. **订阅机制**：需要 SSE 订阅

### 新方案是否适合？

#### ✅ 适合的原因
1. **高并发场景**：新方案可以更好地支持高并发
2. **长时间操作**：资源锁可以长时间持有，不影响其他资源
3. **细粒度控制**：每个资源独立锁，控制更精确

#### ⚠️ 需要注意的问题
1. **资源数量多**：需要管理大量资源锁对象
2. **内存开销**：资源锁对象需要及时清理
3. **实现复杂度**：需要仔细处理资源锁的生命周期

## 推荐方案

### 建议：采用新方案（分段锁 + 资源锁）

**理由：**
1. ✅ **性能更好**：分段锁持有时间更短，并发度更高
2. ✅ **逻辑更清晰**：每个资源有独立锁，符合直觉
3. ✅ **扩展性更好**：可以更好地支持高并发场景

**注意事项：**
1. ⚠️ **资源锁清理**：操作完成后必须清理资源锁对象
2. ⚠️ **死锁预防**：严格按照锁的获取顺序（先分段锁，再资源锁）
3. ⚠️ **内存管理**：监控资源锁的数量，防止内存泄漏

## 实现建议

### 1. 资源锁的生命周期管理

```go
// 创建资源锁
shard.mu.Lock()
rl := shard.getOrCreateResourceLock(key)
shard.mu.Unlock()

// 使用资源锁
rl.mu.Lock()
// ... 操作 ...
rl.mu.Unlock()

// 清理资源锁（操作完成后）
shard.mu.Lock()
if rl.lockInfo == nil && len(rl.queue) == 0 && len(rl.subscribers) == 0 {
    delete(shard.resourceLocks, key)
}
shard.mu.Unlock()
```

### 2. 锁的获取顺序

```go
// 正确的顺序
shard.mu.Lock()  // 1. 先获取分段锁
rl := shard.getOrCreateResourceLock(key)
shard.mu.Unlock()  // 2. 释放分段锁
rl.mu.Lock()  // 3. 再获取资源锁
```

### 3. 错误处理

```go
// 确保资源锁被正确释放
defer rl.mu.Unlock()
// ... 操作 ...
```

## 总结

| 维度 | 当前方案 | 新方案 | 推荐 |
|------|---------|--------|------|
| 性能 | 良好 | 更好 | ✅ 新方案 |
| 内存开销 | 低 | 中等 | ⚠️ 可接受 |
| 实现复杂度 | 低 | 中等 | ⚠️ 需要仔细实现 |
| 并发度 | 32（分段数） | 更高 | ✅ 新方案 |
| 锁粒度 | 粗（分段级别） | 细（资源级别） | ✅ 新方案 |
| 维护成本 | 低 | 中等 | ⚠️ 需要管理生命周期 |

**最终建议**：如果场景需要高并发和细粒度控制，推荐采用新方案。但需要仔细实现资源锁的生命周期管理。

