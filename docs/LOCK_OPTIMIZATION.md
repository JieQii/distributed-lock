# 锁机制优化说明

## 优化前的问题

### 全局锁机制（优化前）

```go
type LockManager struct {
    mu sync.RWMutex  // 全局锁 - 所有操作都需要获取这个锁
    
    locks map[string]*LockInfo
    queues map[string][]*LockRequest
}
```

**问题：**
1. **并发度低**：所有资源（不同镜像层）的操作都需要竞争同一个全局锁
2. **串行化严重**：即使节点A操作层1，节点B操作层2（完全不同的资源），也会因为全局锁而串行执行
3. **性能瓶颈**：在高并发场景下，全局锁成为明显的性能瓶颈

**示例场景：**
- 节点A请求层1的锁 → 获取全局锁 `mu`
- 节点B请求层2的锁 → 等待全局锁 `mu`（即使层1和层2完全无关）
- 节点C请求层3的锁 → 等待全局锁 `mu`

结果：所有请求串行执行，无法充分利用多核CPU。

## 优化后的方案

### 分段锁机制（优化后）

```go
const shardCount = 32  // 32个分段

type resourceShard struct {
    mu sync.RWMutex  // 分段锁 - 只保护该分段内的资源
    
    locks map[string]*LockInfo
    queues map[string][]*LockRequest
}

type LockManager struct {
    shards [shardCount]*resourceShard  // 32个分段
}
```

**优化原理：**
1. **分段哈希**：使用FNV-1a哈希算法，将资源key映射到32个不同的分段
2. **独立锁**：每个分段有自己独立的锁，不同分段之间可以并发访问
3. **提升并发度**：理论上可以支持最多32个不同资源的并发操作

**示例场景（优化后）：**
- 节点A请求层1的锁 → 获取分段3的锁（假设层1哈希到分段3）
- 节点B请求层2的锁 → 获取分段7的锁（假设层2哈希到分段7）
- 节点C请求层3的锁 → 获取分段15的锁（假设层3哈希到分段15）

结果：三个请求可以并发执行，互不干扰！

## 锁的分类

### 1. 全局锁（已优化为分段锁）
- **优化前**：`lm.mu` - 保护整个 `locks` 和 `queues` map
- **优化后**：`shard.mu` - 只保护单个分段内的资源
- **作用**：保护数据结构的并发安全

### 2. 资源锁（逻辑锁）
- **位置**：`shard.locks[key]` - 每个资源（镜像层digest）的逻辑锁
- **作用**：确保同一时刻只有一个节点能操作该资源
- **粒度**：按资源（Type + ResourceID）划分

## 并发度分析

### 优化前
- **理论并发度**：1（所有操作串行）
- **实际场景**：100个节点请求100个不同层 → 全部串行执行

### 优化后
- **理论并发度**：32（32个分段可以并发）
- **实际场景**：100个节点请求100个不同层 → 平均每个分段3-4个请求，大部分可以并发执行

### 性能提升估算
假设：
- 100个不同资源的请求
- 每个操作耗时10ms

**优化前：**
- 总耗时：100 × 10ms = 1000ms（串行）

**优化后：**
- 总耗时：100 / 32 × 10ms ≈ 31.25ms（并发，假设均匀分布）

**性能提升：约32倍**（理论值，实际取决于资源分布）

## 分段数量选择

### 当前设置：32个分段

**选择依据：**
- 平衡并发度和内存开销
- 32是2的幂次方，哈希计算效率高
- 适合中等规模并发（几十到几百个并发请求）

### 调整建议

根据实际场景调整 `shardCount`：

```go
// 低并发场景（< 10个并发请求）
const shardCount = 8

// 中等并发场景（10-100个并发请求）
const shardCount = 32  // 当前设置

// 高并发场景（100-1000个并发请求）
const shardCount = 128

// 极高并发场景（> 1000个并发请求）
const shardCount = 256
```

**注意事项：**
- 分段数过多会增加内存开销（每个分段都有独立的map）
- 分段数过少会降低并发度
- 建议使用2的幂次方（8, 16, 32, 64, 128, 256）

## 哈希分布均匀性

使用FNV-1a哈希算法确保资源key均匀分布到各个分段：

```go
func (lm *LockManager) getShard(key string) *resourceShard {
    h := fnv.New32a()
    h.Write([]byte(key))
    return lm.shards[h.Sum32()%shardCount]
}
```

**优点：**
- 哈希分布均匀，避免热点分段
- 计算速度快，适合高并发场景
- 相同key总是映射到相同分段（一致性）

## 总结

| 特性 | 优化前 | 优化后 |
|------|--------|--------|
| 锁类型 | 全局锁 | 分段锁（32个分段） |
| 并发度 | 1（串行） | 32（理论值） |
| 性能 | 低 | 高（提升约32倍） |
| 适用场景 | 低并发 | 中高并发 |
| 内存开销 | 低 | 中等（32个map） |

**关键改进：**
- ✅ 不同资源可以并发访问
- ✅ 只有相同分段的资源才会竞争锁
- ✅ 大幅提升并发处理能力
- ✅ 保持FIFO队列和资源锁的正确性

