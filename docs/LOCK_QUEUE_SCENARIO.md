# 锁队列场景说明

## 你的理解是正确的 ✅

在实际使用中，如果节点A已经下载完成并释放锁，节点B在重新请求时应该：

1. **先检查本地引用计数**（通过 `ShouldSkipOperation`）
2. **如果 `refCount.Count > 0`** → 跳过操作，**不请求锁**
3. **如果 `refCount.Count == 0`** → 才请求锁

这是正确的流程，可以避免不必要的锁竞争。

## 但是，队列场景确实存在

### 场景：节点B在队列中等待

```
时间线：
T1: 节点A请求锁 → 获得锁，开始下载
T2: 节点B请求锁 → 锁被占用，加入队列，返回 acquired=false
T3: 节点B进入 waitForLock() 轮询等待（每500ms轮询一次）
T4: 节点A下载完成，释放锁
T5: processQueue() 从队列中取出节点B的旧请求，分配锁给节点B
T6: 节点B在轮询中，可能会重新发送 /lock 请求
```

### 问题

在 T6 时刻，节点B重新发送 `/lock` 请求时：
- 锁已经被分配给节点B的旧请求（队列中的请求）
- 节点B的新请求发现锁被占用
- 如果不做特殊处理，节点B的新请求会被再次加入队列

### 我的修复

当节点B的新请求发现锁已被分配给同一节点（NodeID匹配）时，允许它获取锁。这是合理的，因为：
1. 节点B确实需要执行操作（它在队列中等待）
2. 锁已经被分配给节点B，只是通过旧请求分配的
3. 允许新请求获取锁，可以避免重复排队

## 关键点

### 1. 引用计数检查的时机

**正确的流程**：
```
节点B想要下载资源
  ↓
调用 ShouldSkipOperation() 检查引用计数
  ↓
如果 refCount > 0 → 跳过，不请求锁 ✅
如果 refCount == 0 → 请求锁
```

**队列场景**：
```
节点B已经在队列中等待（说明之前检查过，refCount == 0）
  ↓
锁被分配给节点B的旧请求
  ↓
节点B通过轮询重新请求锁
  ↓
此时不应该再次检查引用计数（因为已经在执行流程中）
  ↓
应该允许获取锁 ✅
```

### 2. 时间窗口问题

即使节点A已经下载完成，节点B的本地引用计数可能还没有更新：
- mergerfs 同步延迟
- 节点B还没有检查引用计数
- 网络延迟

在这种情况下，节点B可能仍然认为需要下载，会请求锁。

### 3. 测试脚本的问题

测试脚本 `test-lock.sh` 直接发送HTTP请求，没有经过客户端的 `ShouldSkipOperation` 检查。这导致：
- 测试场景4中，节点B直接请求锁，没有先检查引用计数
- 实际使用中，节点B会先检查引用计数，如果资源已存在，不会请求锁

## 建议

### 1. 保留修复（针对队列场景）

队列场景确实存在，修复是合理的。但应该添加注释说明这个场景的特殊性。

### 2. 改进客户端逻辑

在 `waitForLock` 中，当发现操作已完成且成功时，应该：
- 更新本地引用计数
- 返回 `skipped=true`，而不是重新请求锁

### 3. 改进测试

测试脚本应该模拟实际使用场景：
- 包括引用计数检查
- 测试"资源已存在"时是否跳过操作

## 结论

你的理解是正确的。在实际使用中，如果节点A已经下载完成，节点B应该通过引用计数检查跳过操作，不应该再次请求锁。

但是，队列等待场景确实存在，当节点B在队列中等待时，如果锁被分配给它的旧请求，节点B的新请求应该能够识别并获取锁。

我的修复是针对队列场景的，是合理的。但应该配合改进客户端逻辑，确保在"操作已完成"时正确更新引用计数并跳过操作。

